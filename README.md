
## è®¡ç®—æœºå‰æ²¿æŠ€æœ¯è¯¾ç¨‹ å¤ç°å·¥ä½œ

## å¤ç°è®ºæ–‡ï¼šSemantically Grounded Object Matching for Robust Robotic Scene Rearrangement [ğŸ§·](https://arxiv.org/abs/2111.07975)


### åªè¿›è¡Œç‰©ä½“åŒ¹é…ï¼š

> ç¯å¢ƒä¾èµ–

    python >= 3.6
    pytorch >= 1.7.1
    clip (https://github.com/openai/CLIP)

> æ ¸å¿ƒä»£ç 

ç‰©ä½“åŒ¹é…çš„å¤ç°ä»£ç åœ¨`VM`ï¼ˆvisual matchingï¼‰æ–‡ä»¶å¤¹ä¸‹ï¼Œå…¶ä¸­[`matcher.py`](./VM/matcher.py)é‡Œé¢å®ç°äº†ç‰©ä½“åŒ¹é…çš„ç®—æ³•ï¼Œä½ å¯ä»¥å‚è€ƒ`evaluate_lvis.py`ã€‚

```python
from VM.matcher import VisualMatcher

matcher = VisualMatcher()

source_list = xxx # sourse images
target_list = xxx # goal images
label_list = xxx # object labels
use_text = True

source_ids, target_ids = matcher.match_images( source_list, target_list, label_list, use_text )
```

> æµ‹è¯•æ•°æ®é›†

è¯·å‚è€ƒ`VM/data/README.md`ä¸‹è½½æ•°æ®é›†åè¿›è¡Œå¤„ç†ã€‚


### è¿›è¡Œæœºå™¨äººé‡æ’åˆ—å®éªŒï¼š

> ç¯å¢ƒä¾èµ–

    python >= 3.6
    pyvista
    pytorch >= 1.7.1
    clip (https://github.com/openai/CLIP)
    
> å®‰è£…æ¨¡æ‹Ÿç¯å¢ƒï¼ˆè¦æ±‚RTXæ˜¾å¡ï¼‰ï¼š

omiverse isaac sim (https://developer.nvidia.com/isaac-sim)

> æ ¸å¿ƒä»£ç 

`robot`ï¼šå†…æ˜¯isaac simçš„æ¨¡æ‹Ÿç¯å¢ƒæ§åˆ¶ä»£ç 

`UOC`ï¼šä¿®æ”¹è‡ª[https://github.com/NVlabs/UnseenObjectClustering](https://github.com/NVlabs/UnseenObjectClustering)çš„ä»£ç ï¼Œæˆ‘åœ¨é‡Œé¢å†™äº†ä¸ª`app.py`ï¼Œä»ä¸­æå–å‡ºäº†ä¸€ä¸ª`Segmenter`ç±»ä½œä¸ºå®ä¾‹åˆ†å‰²æ¨¡å—ã€‚ä½¿ç”¨å‰è¯·ä¸‹è½½å¥½ä»–ä»¬çš„è®­ç»ƒæƒé‡ï¼Œæ”¾åˆ°`UOC/data/checkpoints`ä¸‹

`main.py`ï¼šæœºå™¨äººé‡æ’åˆ—çš„ä¸»ä»£ç 

`ui.py`ï¼šè®¾ç½®isaac simçš„ç•Œé¢ä»£ç 

`run.bat`ï¼šæ‰§è¡Œ`main.py`çš„å‘½ä»¤


